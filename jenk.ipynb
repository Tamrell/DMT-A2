{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from codebase import io\n",
    "from codebase.evaluation import ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([  2,   5,   8,  11,  14,  17,  20,  23,  26,  29,  32,  35,  38,\n",
      "             41,  44,  47,  50,  53,  56,  59,  62,  65,  68,  71,  74,  77,\n",
      "             80,  83,  86,  89,  92,  95,  98, 101, 104, 107, 110, 113, 116,\n",
      "            119, 122, 125, 128, 131, 134, 137, 140, 143, 146, 149, 152, 155,\n",
      "            158, 161, 164, 167, 170, 173, 176, 179, 182, 185, 188, 191, 194,\n",
      "            197, 200, 203, 206, 209, 212, 215, 218, 221, 224, 227, 230, 233,\n",
      "            236, 239, 242, 245, 248, 251, 254, 257, 260, 263, 266, 269, 272,\n",
      "            275, 278, 281],\n",
      "           dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "tracking = io.TRACKING_DF\n",
    "start_model = 2\n",
    "model_ids = tracking[start_model::3].index\n",
    "print(model_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve average results over run\n",
    "results = io.load_jsons(model_ids)\n",
    "for c in results:\n",
    "    results[c] = results[c].apply(lambda x: np.mean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 48, model: 146\n",
      "Calculating NDCG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (22412 of 22412) |##################| Elapsed Time: 0:00:03 Time:  0:00:03\n",
      "E:\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 49, model: 149\n",
      "Calculating NDCG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (21900 of 21900) |##################| Elapsed Time: 0:00:03 Time:  0:00:03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 50, model: 152\n",
      "Calculating NDCG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (22122 of 22122) |##################| Elapsed Time: 0:00:03 Time:  0:00:03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 51, model: 155\n",
      "Calculating NDCG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (22412 of 22412) |##################| Elapsed Time: 0:00:03 Time:  0:00:03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 52, model: 158\n",
      "Calculating NDCG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (21900 of 21900) |##################| Elapsed Time: 0:00:03 Time:  0:00:03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 53, model: 161\n",
      "Calculating NDCG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (22122 of 22122) |##################| Elapsed Time: 0:00:03 Time:  0:00:03\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Merge tracking and results on model_id\n",
    "full_results = pd.merge(tracking, results, left_index=True, right_index=True)\n",
    "\n",
    "# Recalculate true ndcg values for relevance changes\n",
    "for i, model in enumerate(full_results.index):\n",
    "    if full_results[\"uniform_relevance\"].iloc[i] > 0 or full_results[\"artificial_relevance\"].iloc[i] > 0:\n",
    "        print(f\"i: {i}, model: {model}\")\n",
    "        full_results[\"val_ndcg@5\"].iloc[i] = ndcg(io.load_val_predictions(model))\n",
    "\n",
    "# Group folds by averaging over them (every 3 results are 1 k-folds run)\n",
    "results_reset = full_results.reset_index()\n",
    "grouped_results = results_reset.groupby(results_reset.index//3).mean()\n",
    "\n",
    "# Get default parameters and their values\n",
    "params = [c for c in tracking.columns if not c == \"device\"]\n",
    "default_params = tracking.head(1)\n",
    "\n",
    "# Print out default parameters\n",
    "# for p in params:\n",
    "#     print(p, default_params[p].iloc[0])\n",
    "\n",
    "# Define function to get more insightfull data format\n",
    "def find_mutation(parameters, default, row):\n",
    "    \"\"\"Finds what parameter was mutated in the row and what value it is\"\"\"\n",
    "\n",
    "    # Return name of parameter that was mutated\n",
    "    for p in parameters:\n",
    "        if not default[p].iloc[0] == row[p]:\n",
    "            return p, row[p]\n",
    "    return None, None\n",
    "\n",
    "\n",
    "# Create \"mutation\" and \"mutation value\" column for instant mutation recognition\n",
    "mutations = []\n",
    "mutation_values = []\n",
    "for _, row in grouped_results.iterrows():\n",
    "    mut = find_mutation(params, default_params, row)\n",
    "    mutations.append(mut[0])\n",
    "    mutation_values.append(mut[1])\n",
    "grouped_results[\"mutation\"] = mutations\n",
    "grouped_results[\"mutation value\"] = mutation_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default settings performance mean: 0.30478896638797875, std: 0.09307461135705937\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>mutation</th>\n",
       "      <th>mutation value</th>\n",
       "      <th>epoch_time</th>\n",
       "      <th>trn_ndcg@5</th>\n",
       "      <th>val_ndcg@5</th>\n",
       "      <th>val@5_diff_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>108</td>\n",
       "      <td>0.428676</td>\n",
       "      <td>0.377042</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>layer_size</td>\n",
       "      <td>20.00000</td>\n",
       "      <td>63</td>\n",
       "      <td>0.406651</td>\n",
       "      <td>0.368609</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23</td>\n",
       "      <td>layer_size</td>\n",
       "      <td>320.00000</td>\n",
       "      <td>170</td>\n",
       "      <td>0.448108</td>\n",
       "      <td>0.372058</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>learning_rate</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>111</td>\n",
       "      <td>0.459808</td>\n",
       "      <td>0.365023</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>learning_rate</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>113</td>\n",
       "      <td>0.379263</td>\n",
       "      <td>0.347650</td>\n",
       "      <td>-0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50</td>\n",
       "      <td>layers</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>76</td>\n",
       "      <td>0.425777</td>\n",
       "      <td>0.381839</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>59</td>\n",
       "      <td>layers</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>142</td>\n",
       "      <td>0.432364</td>\n",
       "      <td>0.378887</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>68</td>\n",
       "      <td>resnet</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>109</td>\n",
       "      <td>0.417086</td>\n",
       "      <td>0.365222</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>77</td>\n",
       "      <td>attention_layer_idx</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>93</td>\n",
       "      <td>0.430246</td>\n",
       "      <td>0.376584</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>86</td>\n",
       "      <td>attention_layer_idx</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>112</td>\n",
       "      <td>0.431791</td>\n",
       "      <td>0.378251</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>95</td>\n",
       "      <td>attention_layer_idx</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>111</td>\n",
       "      <td>0.427447</td>\n",
       "      <td>0.381231</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>104</td>\n",
       "      <td>attention_layer_idx</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>92</td>\n",
       "      <td>0.430646</td>\n",
       "      <td>0.379938</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>113</td>\n",
       "      <td>relu_slope</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>111</td>\n",
       "      <td>0.429905</td>\n",
       "      <td>0.378960</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>122</td>\n",
       "      <td>relu_slope</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>110</td>\n",
       "      <td>0.430953</td>\n",
       "      <td>0.373536</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>131</td>\n",
       "      <td>lambda_batch_size</td>\n",
       "      <td>50.00000</td>\n",
       "      <td>125</td>\n",
       "      <td>0.443260</td>\n",
       "      <td>0.377328</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>140</td>\n",
       "      <td>lambda_batch_size</td>\n",
       "      <td>450.00000</td>\n",
       "      <td>91</td>\n",
       "      <td>0.407735</td>\n",
       "      <td>0.365648</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>149</td>\n",
       "      <td>artificial_relevance</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>112</td>\n",
       "      <td>0.197861</td>\n",
       "      <td>0.338422</td>\n",
       "      <td>-0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>158</td>\n",
       "      <td>uniform_relevance</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>113</td>\n",
       "      <td>0.429835</td>\n",
       "      <td>0.373613</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>167</td>\n",
       "      <td>split_on_random_bool</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>119</td>\n",
       "      <td>0.424747</td>\n",
       "      <td>0.375680</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>176</td>\n",
       "      <td>ndcg@5</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>122</td>\n",
       "      <td>0.431751</td>\n",
       "      <td>0.380817</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>185</td>\n",
       "      <td>use_priors</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>119</td>\n",
       "      <td>0.350038</td>\n",
       "      <td>0.351869</td>\n",
       "      <td>-0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>194</td>\n",
       "      <td>normalize_per_subset</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>116</td>\n",
       "      <td>0.400464</td>\n",
       "      <td>0.345087</td>\n",
       "      <td>-0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>203</td>\n",
       "      <td>datetime_shenanigans</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>116</td>\n",
       "      <td>0.433416</td>\n",
       "      <td>0.373254</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>212</td>\n",
       "      <td>summarize_competitors</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>118</td>\n",
       "      <td>0.431386</td>\n",
       "      <td>0.372697</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>221</td>\n",
       "      <td>travelling_within_country_bool</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>116</td>\n",
       "      <td>0.430744</td>\n",
       "      <td>0.378202</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>230</td>\n",
       "      <td>occurrence conversion</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>115</td>\n",
       "      <td>0.429121</td>\n",
       "      <td>0.377272</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>239</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.176112</td>\n",
       "      <td>0.168077</td>\n",
       "      <td>-2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>248</td>\n",
       "      <td>layer_size</td>\n",
       "      <td>60.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.208864</td>\n",
       "      <td>0.180319</td>\n",
       "      <td>-2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>257</td>\n",
       "      <td>layer_size</td>\n",
       "      <td>120.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.204632</td>\n",
       "      <td>0.174903</td>\n",
       "      <td>-2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>266</td>\n",
       "      <td>layer_size</td>\n",
       "      <td>240.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.107572</td>\n",
       "      <td>0.165864</td>\n",
       "      <td>-2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>275</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>129</td>\n",
       "      <td>0.404944</td>\n",
       "      <td>0.337478</td>\n",
       "      <td>-0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>281</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>115</td>\n",
       "      <td>0.407108</td>\n",
       "      <td>0.336560</td>\n",
       "      <td>-0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model_id                        mutation  mutation value  epoch_time  \\\n",
       "0          5                            None             NaN         108   \n",
       "1         14                      layer_size        20.00000          63   \n",
       "2         23                      layer_size       320.00000         170   \n",
       "3         32                   learning_rate         0.00100         111   \n",
       "4         41                   learning_rate         0.00001         113   \n",
       "5         50                          layers         2.00000          76   \n",
       "6         59                          layers         8.00000         142   \n",
       "7         68                          resnet         0.00000         109   \n",
       "8         77             attention_layer_idx        -1.00000          93   \n",
       "9         86             attention_layer_idx         0.00000         112   \n",
       "10        95             attention_layer_idx         2.00000         111   \n",
       "11       104             attention_layer_idx         3.00000          92   \n",
       "12       113                      relu_slope         0.00100         111   \n",
       "13       122                      relu_slope         0.10000         110   \n",
       "14       131               lambda_batch_size        50.00000         125   \n",
       "15       140               lambda_batch_size       450.00000          91   \n",
       "16       149            artificial_relevance         1.00000         112   \n",
       "17       158               uniform_relevance         1.00000         113   \n",
       "18       167            split_on_random_bool         1.00000         119   \n",
       "19       176                          ndcg@5         1.00000         122   \n",
       "20       185                      use_priors         0.00000         119   \n",
       "21       194            normalize_per_subset         0.00000         116   \n",
       "22       203            datetime_shenanigans         0.00000         116   \n",
       "23       212           summarize_competitors         0.00000         118   \n",
       "24       221  travelling_within_country_bool         0.00000         116   \n",
       "25       230           occurrence conversion         0.00000         115   \n",
       "26       239                            None             NaN           0   \n",
       "27       248                      layer_size        60.00000           0   \n",
       "28       257                      layer_size       120.00000           0   \n",
       "29       266                      layer_size       240.00000           0   \n",
       "30       275                            None             NaN         129   \n",
       "31       281                            None             NaN         115   \n",
       "\n",
       "    trn_ndcg@5  val_ndcg@5  val@5_diff_std  \n",
       "0     0.428676    0.377042             0.0  \n",
       "1     0.406651    0.368609            -0.1  \n",
       "2     0.448108    0.372058            -0.1  \n",
       "3     0.459808    0.365023            -0.1  \n",
       "4     0.379263    0.347650            -0.3  \n",
       "5     0.425777    0.381839             0.1  \n",
       "6     0.432364    0.378887             0.0  \n",
       "7     0.417086    0.365222            -0.1  \n",
       "8     0.430246    0.376584            -0.0  \n",
       "9     0.431791    0.378251             0.0  \n",
       "10    0.427447    0.381231             0.0  \n",
       "11    0.430646    0.379938             0.0  \n",
       "12    0.429905    0.378960             0.0  \n",
       "13    0.430953    0.373536            -0.0  \n",
       "14    0.443260    0.377328             0.0  \n",
       "15    0.407735    0.365648            -0.1  \n",
       "16    0.197861    0.338422            -0.4  \n",
       "17    0.429835    0.373613            -0.0  \n",
       "18    0.424747    0.375680            -0.0  \n",
       "19    0.431751    0.380817             0.0  \n",
       "20    0.350038    0.351869            -0.3  \n",
       "21    0.400464    0.345087            -0.3  \n",
       "22    0.433416    0.373254            -0.0  \n",
       "23    0.431386    0.372697            -0.0  \n",
       "24    0.430744    0.378202             0.0  \n",
       "25    0.429121    0.377272             0.0  \n",
       "26    0.176112    0.168077            -2.2  \n",
       "27    0.208864    0.180319            -2.1  \n",
       "28    0.204632    0.174903            -2.2  \n",
       "29    0.107572    0.165864            -2.3  \n",
       "30    0.404944    0.337478            -0.4  \n",
       "31    0.407108    0.336560            -0.4  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_default_val_ndcg = grouped_results[grouped_results.isna()[\"mutation value\"]][\"val_ndcg@5\"].std()\n",
    "mu_default_val_ndcg = grouped_results[grouped_results.isna()[\"mutation value\"]][\"val_ndcg@5\"].mean()\n",
    "print(f\"default settings performance mean: {mu_default_val_ndcg}, std: {std_default_val_ndcg}\")\n",
    "\n",
    "grouped_results[\"val@5_diff_std\"] = ((grouped_results[\"val_ndcg@5\"] - grouped_results[\"val_ndcg@5\"].iloc[0])/std_default_val_ndcg).round(1)\n",
    "grouped_results[\"epoch_time\"] = grouped_results[\"epoch_time\"].round().astype(int)\n",
    "grouped_results[\"model_id\"] = grouped_results[\"index\"].astype(int)\n",
    "\n",
    "relevant_cols = [\"model_id\", \n",
    "                 \"mutation\",\n",
    "                 \"mutation value\",\n",
    "                 \"epoch_time\",\n",
    "#                  \"trn_ndcg\", \n",
    "#                  \"val_ndcg\", \n",
    "                 \"trn_ndcg@5\", \n",
    "                 \"val_ndcg@5\",\n",
    "                 \"val@5_diff_std\"]\n",
    "grouped_results[relevant_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order the results by their validation ndcg\n",
    "ordered = full_results.sort_values(by='val_ndcg@5', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for val in ordered.head(0):\n",
    "#     print(f\"{val}: {ordered.head(1)[val].item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>artificial_relevance</th>\n",
       "      <th>attention_layer_idx</th>\n",
       "      <th>datetime_shenanigans</th>\n",
       "      <th>epochs</th>\n",
       "      <th>exp_ver</th>\n",
       "      <th>lambda_batch_size</th>\n",
       "      <th>layer_size</th>\n",
       "      <th>layers</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>...</th>\n",
       "      <th>use_priors</th>\n",
       "      <th>epoch_time</th>\n",
       "      <th>trn_ndcg</th>\n",
       "      <th>trn_ndcg@5</th>\n",
       "      <th>val_ndcg</th>\n",
       "      <th>val_ndcg@5</th>\n",
       "      <th>mutation</th>\n",
       "      <th>mutation value</th>\n",
       "      <th>val@5_diff_std</th>\n",
       "      <th>model_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>108</td>\n",
       "      <td>0.990812</td>\n",
       "      <td>0.428676</td>\n",
       "      <td>0.826461</td>\n",
       "      <td>0.377042</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63</td>\n",
       "      <td>1.097771</td>\n",
       "      <td>0.406651</td>\n",
       "      <td>0.780376</td>\n",
       "      <td>0.368609</td>\n",
       "      <td>layer_size</td>\n",
       "      <td>20.00000</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>170</td>\n",
       "      <td>0.799757</td>\n",
       "      <td>0.448108</td>\n",
       "      <td>0.771158</td>\n",
       "      <td>0.372058</td>\n",
       "      <td>layer_size</td>\n",
       "      <td>320.00000</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>111</td>\n",
       "      <td>1.078846</td>\n",
       "      <td>0.459808</td>\n",
       "      <td>0.796936</td>\n",
       "      <td>0.365023</td>\n",
       "      <td>learning_rate</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>113</td>\n",
       "      <td>1.123546</td>\n",
       "      <td>0.379263</td>\n",
       "      <td>0.775536</td>\n",
       "      <td>0.347650</td>\n",
       "      <td>learning_rate</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>76</td>\n",
       "      <td>0.661281</td>\n",
       "      <td>0.425777</td>\n",
       "      <td>0.769470</td>\n",
       "      <td>0.381839</td>\n",
       "      <td>layers</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>142</td>\n",
       "      <td>1.101151</td>\n",
       "      <td>0.432364</td>\n",
       "      <td>0.766282</td>\n",
       "      <td>0.378887</td>\n",
       "      <td>layers</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>109</td>\n",
       "      <td>1.099439</td>\n",
       "      <td>0.417086</td>\n",
       "      <td>0.832742</td>\n",
       "      <td>0.365222</td>\n",
       "      <td>resnet</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>77</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>93</td>\n",
       "      <td>1.219488</td>\n",
       "      <td>0.430246</td>\n",
       "      <td>0.780552</td>\n",
       "      <td>0.376584</td>\n",
       "      <td>attention_layer_idx</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>112</td>\n",
       "      <td>1.253084</td>\n",
       "      <td>0.431791</td>\n",
       "      <td>0.811049</td>\n",
       "      <td>0.378251</td>\n",
       "      <td>attention_layer_idx</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>111</td>\n",
       "      <td>1.316787</td>\n",
       "      <td>0.427447</td>\n",
       "      <td>0.809125</td>\n",
       "      <td>0.381231</td>\n",
       "      <td>attention_layer_idx</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92</td>\n",
       "      <td>1.153153</td>\n",
       "      <td>0.430646</td>\n",
       "      <td>0.773140</td>\n",
       "      <td>0.379938</td>\n",
       "      <td>attention_layer_idx</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>113</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>111</td>\n",
       "      <td>1.118558</td>\n",
       "      <td>0.429905</td>\n",
       "      <td>0.782818</td>\n",
       "      <td>0.378960</td>\n",
       "      <td>relu_slope</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>122</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110</td>\n",
       "      <td>1.138927</td>\n",
       "      <td>0.430953</td>\n",
       "      <td>0.778174</td>\n",
       "      <td>0.373536</td>\n",
       "      <td>relu_slope</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>131</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>125</td>\n",
       "      <td>0.696861</td>\n",
       "      <td>0.443260</td>\n",
       "      <td>0.823726</td>\n",
       "      <td>0.377328</td>\n",
       "      <td>lambda_batch_size</td>\n",
       "      <td>50.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>140</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>91</td>\n",
       "      <td>1.100779</td>\n",
       "      <td>0.407735</td>\n",
       "      <td>0.817161</td>\n",
       "      <td>0.365648</td>\n",
       "      <td>lambda_batch_size</td>\n",
       "      <td>450.00000</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>149</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>112</td>\n",
       "      <td>0.143898</td>\n",
       "      <td>0.197861</td>\n",
       "      <td>-0.125815</td>\n",
       "      <td>0.338422</td>\n",
       "      <td>artificial_relevance</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>158</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>113</td>\n",
       "      <td>0.998692</td>\n",
       "      <td>0.429835</td>\n",
       "      <td>0.813428</td>\n",
       "      <td>0.373613</td>\n",
       "      <td>uniform_relevance</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>119</td>\n",
       "      <td>1.333891</td>\n",
       "      <td>0.424747</td>\n",
       "      <td>0.784668</td>\n",
       "      <td>0.375680</td>\n",
       "      <td>split_on_random_bool</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>122</td>\n",
       "      <td>1.226558</td>\n",
       "      <td>0.431751</td>\n",
       "      <td>0.769470</td>\n",
       "      <td>0.380817</td>\n",
       "      <td>ndcg@5</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>119</td>\n",
       "      <td>0.622384</td>\n",
       "      <td>0.350038</td>\n",
       "      <td>1.044114</td>\n",
       "      <td>0.351869</td>\n",
       "      <td>use_priors</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>194</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>116</td>\n",
       "      <td>1.136169</td>\n",
       "      <td>0.400464</td>\n",
       "      <td>0.788177</td>\n",
       "      <td>0.345087</td>\n",
       "      <td>normalize_per_subset</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>203</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>116</td>\n",
       "      <td>0.992764</td>\n",
       "      <td>0.433416</td>\n",
       "      <td>0.750252</td>\n",
       "      <td>0.373254</td>\n",
       "      <td>datetime_shenanigans</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>212</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>118</td>\n",
       "      <td>0.838671</td>\n",
       "      <td>0.431386</td>\n",
       "      <td>0.748154</td>\n",
       "      <td>0.372697</td>\n",
       "      <td>summarize_competitors</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>116</td>\n",
       "      <td>0.891131</td>\n",
       "      <td>0.430744</td>\n",
       "      <td>0.774282</td>\n",
       "      <td>0.378202</td>\n",
       "      <td>travelling_within_country_bool</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>115</td>\n",
       "      <td>0.906030</td>\n",
       "      <td>0.429121</td>\n",
       "      <td>0.762554</td>\n",
       "      <td>0.377272</td>\n",
       "      <td>occurrence conversion</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>239</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.656155</td>\n",
       "      <td>0.176112</td>\n",
       "      <td>0.959467</td>\n",
       "      <td>0.168077</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.655873</td>\n",
       "      <td>0.208864</td>\n",
       "      <td>0.935925</td>\n",
       "      <td>0.180319</td>\n",
       "      <td>layer_size</td>\n",
       "      <td>60.00000</td>\n",
       "      <td>-2.1</td>\n",
       "      <td>248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>257</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.864317</td>\n",
       "      <td>0.204632</td>\n",
       "      <td>0.954352</td>\n",
       "      <td>0.174903</td>\n",
       "      <td>layer_size</td>\n",
       "      <td>120.00000</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>266</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00040</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.485952</td>\n",
       "      <td>0.107572</td>\n",
       "      <td>0.551356</td>\n",
       "      <td>0.165864</td>\n",
       "      <td>layer_size</td>\n",
       "      <td>240.00000</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>275</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>129</td>\n",
       "      <td>1.035268</td>\n",
       "      <td>0.404944</td>\n",
       "      <td>0.838542</td>\n",
       "      <td>0.337478</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>281</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>115</td>\n",
       "      <td>0.525745</td>\n",
       "      <td>0.407108</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.336560</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32 rows  29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  artificial_relevance  attention_layer_idx  datetime_shenanigans  \\\n",
       "0       5                   0.0                  1.0                   1.0   \n",
       "1      14                   0.0                  1.0                   1.0   \n",
       "2      23                   0.0                  1.0                   1.0   \n",
       "3      32                   0.0                  1.0                   1.0   \n",
       "4      41                   0.0                  1.0                   1.0   \n",
       "5      50                   0.0                  1.0                   1.0   \n",
       "6      59                   0.0                  1.0                   1.0   \n",
       "7      68                   0.0                  1.0                   1.0   \n",
       "8      77                   0.0                 -1.0                   1.0   \n",
       "9      86                   0.0                  0.0                   1.0   \n",
       "10     95                   0.0                  2.0                   1.0   \n",
       "11    104                   0.0                  3.0                   1.0   \n",
       "12    113                   0.0                  1.0                   1.0   \n",
       "13    122                   0.0                  1.0                   1.0   \n",
       "14    131                   0.0                  1.0                   1.0   \n",
       "15    140                   0.0                  1.0                   1.0   \n",
       "16    149                   1.0                  1.0                   1.0   \n",
       "17    158                   0.0                  1.0                   1.0   \n",
       "18    167                   0.0                  1.0                   1.0   \n",
       "19    176                   0.0                  1.0                   1.0   \n",
       "20    185                   0.0                  1.0                   1.0   \n",
       "21    194                   0.0                  1.0                   1.0   \n",
       "22    203                   0.0                  1.0                   0.0   \n",
       "23    212                   0.0                  1.0                   1.0   \n",
       "24    221                   0.0                  1.0                   1.0   \n",
       "25    230                   0.0                  1.0                   1.0   \n",
       "26    239                   0.0                  1.0                   1.0   \n",
       "27    248                   0.0                  1.0                   1.0   \n",
       "28    257                   0.0                  1.0                   1.0   \n",
       "29    266                   0.0                  1.0                   1.0   \n",
       "30    275                   0.0                  1.0                   1.0   \n",
       "31    281                   0.0                  1.0                   1.0   \n",
       "\n",
       "    epochs  exp_ver  lambda_batch_size  layer_size  layers  learning_rate  \\\n",
       "0      3.0      0.0              150.0        80.0     4.0        0.00010   \n",
       "1      3.0      0.0              150.0        20.0     4.0        0.00010   \n",
       "2      3.0      0.0              150.0       320.0     4.0        0.00010   \n",
       "3      3.0      0.0              150.0        80.0     4.0        0.00100   \n",
       "4      3.0      0.0              150.0        80.0     4.0        0.00001   \n",
       "5      3.0      0.0              150.0        80.0     2.0        0.00010   \n",
       "6      3.0      0.0              150.0        80.0     8.0        0.00010   \n",
       "7      3.0      0.0              150.0        80.0     4.0        0.00010   \n",
       "8      3.0      0.0              150.0        80.0     4.0        0.00010   \n",
       "9      3.0      0.0              150.0        80.0     4.0        0.00010   \n",
       "10     3.0      0.0              150.0        80.0     4.0        0.00010   \n",
       "11     3.0      0.0              150.0        80.0     4.0        0.00010   \n",
       "12     3.0      0.0              150.0        80.0     4.0        0.00010   \n",
       "13     3.0      0.0              150.0        80.0     4.0        0.00010   \n",
       "14     3.0      0.0               50.0        80.0     4.0        0.00010   \n",
       "15     3.0      0.0              450.0        80.0     4.0        0.00010   \n",
       "16     3.0      0.0              150.0        80.0     4.0        0.00010   \n",
       "17     3.0      0.0              150.0        80.0     4.0        0.00010   \n",
       "18     3.0      0.0              150.0        80.0     4.0        0.00010   \n",
       "19     3.0      0.0              150.0        80.0     4.0        0.00010   \n",
       "20     3.0      0.0              150.0        80.0     4.0        0.00010   \n",
       "21     3.0      0.0              150.0        80.0     4.0        0.00010   \n",
       "22     3.0      0.0              150.0        80.0     4.0        0.00010   \n",
       "23     3.0      0.0              150.0        80.0     4.0        0.00010   \n",
       "24     3.0      0.0              150.0        80.0     4.0        0.00010   \n",
       "25     3.0      0.0              150.0        80.0     4.0        0.00010   \n",
       "26     3.0      0.0              150.0        80.0     4.0        0.00010   \n",
       "27     3.0      0.0              150.0        60.0     4.0        0.00010   \n",
       "28     3.0      0.0              150.0       120.0     4.0        0.00010   \n",
       "29     3.0      0.0              150.0       240.0     4.0        0.00040   \n",
       "30     3.0      0.0              150.0        80.0     4.0        0.00010   \n",
       "31     3.0      0.0              150.0        80.0     4.0        0.00010   \n",
       "\n",
       "    ...  use_priors  epoch_time  trn_ndcg  trn_ndcg@5  val_ndcg  val_ndcg@5  \\\n",
       "0   ...         1.0         108  0.990812    0.428676  0.826461    0.377042   \n",
       "1   ...         1.0          63  1.097771    0.406651  0.780376    0.368609   \n",
       "2   ...         1.0         170  0.799757    0.448108  0.771158    0.372058   \n",
       "3   ...         1.0         111  1.078846    0.459808  0.796936    0.365023   \n",
       "4   ...         1.0         113  1.123546    0.379263  0.775536    0.347650   \n",
       "5   ...         1.0          76  0.661281    0.425777  0.769470    0.381839   \n",
       "6   ...         1.0         142  1.101151    0.432364  0.766282    0.378887   \n",
       "7   ...         1.0         109  1.099439    0.417086  0.832742    0.365222   \n",
       "8   ...         1.0          93  1.219488    0.430246  0.780552    0.376584   \n",
       "9   ...         1.0         112  1.253084    0.431791  0.811049    0.378251   \n",
       "10  ...         1.0         111  1.316787    0.427447  0.809125    0.381231   \n",
       "11  ...         1.0          92  1.153153    0.430646  0.773140    0.379938   \n",
       "12  ...         1.0         111  1.118558    0.429905  0.782818    0.378960   \n",
       "13  ...         1.0         110  1.138927    0.430953  0.778174    0.373536   \n",
       "14  ...         1.0         125  0.696861    0.443260  0.823726    0.377328   \n",
       "15  ...         1.0          91  1.100779    0.407735  0.817161    0.365648   \n",
       "16  ...         1.0         112  0.143898    0.197861 -0.125815    0.338422   \n",
       "17  ...         1.0         113  0.998692    0.429835  0.813428    0.373613   \n",
       "18  ...         1.0         119  1.333891    0.424747  0.784668    0.375680   \n",
       "19  ...         1.0         122  1.226558    0.431751  0.769470    0.380817   \n",
       "20  ...         0.0         119  0.622384    0.350038  1.044114    0.351869   \n",
       "21  ...         1.0         116  1.136169    0.400464  0.788177    0.345087   \n",
       "22  ...         1.0         116  0.992764    0.433416  0.750252    0.373254   \n",
       "23  ...         1.0         118  0.838671    0.431386  0.748154    0.372697   \n",
       "24  ...         1.0         116  0.891131    0.430744  0.774282    0.378202   \n",
       "25  ...         1.0         115  0.906030    0.429121  0.762554    0.377272   \n",
       "26  ...         1.0           0  0.656155    0.176112  0.959467    0.168077   \n",
       "27  ...         1.0           0  0.655873    0.208864  0.935925    0.180319   \n",
       "28  ...         1.0           0  0.864317    0.204632  0.954352    0.174903   \n",
       "29  ...         1.0           0  0.485952    0.107572  0.551356    0.165864   \n",
       "30  ...         1.0         129  1.035268    0.404944  0.838542    0.337478   \n",
       "31  ...         1.0         115  0.525745    0.407108  0.750000    0.336560   \n",
       "\n",
       "                          mutation  mutation value  val@5_diff_std  model_id  \n",
       "0                             None             NaN             0.0         5  \n",
       "1                       layer_size        20.00000            -0.1        14  \n",
       "2                       layer_size       320.00000            -0.1        23  \n",
       "3                    learning_rate         0.00100            -0.1        32  \n",
       "4                    learning_rate         0.00001            -0.3        41  \n",
       "5                           layers         2.00000             0.1        50  \n",
       "6                           layers         8.00000             0.0        59  \n",
       "7                           resnet         0.00000            -0.1        68  \n",
       "8              attention_layer_idx        -1.00000            -0.0        77  \n",
       "9              attention_layer_idx         0.00000             0.0        86  \n",
       "10             attention_layer_idx         2.00000             0.0        95  \n",
       "11             attention_layer_idx         3.00000             0.0       104  \n",
       "12                      relu_slope         0.00100             0.0       113  \n",
       "13                      relu_slope         0.10000            -0.0       122  \n",
       "14               lambda_batch_size        50.00000             0.0       131  \n",
       "15               lambda_batch_size       450.00000            -0.1       140  \n",
       "16            artificial_relevance         1.00000            -0.4       149  \n",
       "17               uniform_relevance         1.00000            -0.0       158  \n",
       "18            split_on_random_bool         1.00000            -0.0       167  \n",
       "19                          ndcg@5         1.00000             0.0       176  \n",
       "20                      use_priors         0.00000            -0.3       185  \n",
       "21            normalize_per_subset         0.00000            -0.3       194  \n",
       "22            datetime_shenanigans         0.00000            -0.0       203  \n",
       "23           summarize_competitors         0.00000            -0.0       212  \n",
       "24  travelling_within_country_bool         0.00000             0.0       221  \n",
       "25           occurrence conversion         0.00000             0.0       230  \n",
       "26                            None             NaN            -2.2       239  \n",
       "27                      layer_size        60.00000            -2.1       248  \n",
       "28                      layer_size       120.00000            -2.2       257  \n",
       "29                      layer_size       240.00000            -2.3       266  \n",
       "30                            None             NaN            -0.4       275  \n",
       "31                            None             NaN            -0.4       281  \n",
       "\n",
       "[32 rows x 29 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-9-92e709d6de3b>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-9-92e709d6de3b>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    relevant = ordered[ordered[\"val_ndcg@5\"] > ordered[\"val_ndcg@5\"][0]\u001b[0m\n\u001b[1;37m                                                                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "relevant = ordered[ordered[\"val_ndcg@5\"] > ordered[\"val_ndcg@5\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
